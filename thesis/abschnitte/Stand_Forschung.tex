\section{Grundlagen}

\subsection{Genetische Algorithmen}

Genetische Algorithmen sind eine Klasse von Optimierungsalgorithmen, die sich an den Mechanismen der natürlichen Evolution orientieren.
Namentlich Mutation, Crossover und Selektion.
Die Begrifflichkeiten orientieren sich entsprechen an der natürlichen Evolution.
Genetische Algorithmen arbeiten typischerweise mit Populationen aus Individuen, welche sich über Generationen entwickeln.
Jedes Individuum besitzt einen Genotypen sowie einen Phänotypen.
\todo{Bild geno phäno}
Der Genotyp eines Individuums ist typischerweise ein Vektor, das Genom des Individuums genannt, der aus einzelnen Zahlen, den Genen des Individuums, besteht. Dieser stellt die genetischen Informationen eines Individuums dar. Daneben existiert in genetischen Algorithmen eine Mapping-Funktion mit der eine Genotyp in einen Phänotyp, der nichts anderes als eine konkrete Lösung des Optimierungsproblems ist, übersetzt werden kann.

Die Mechanismen der Mutation und des Crossovers agieren auf der Ebene des Genotyps.
Mutation beschreibt die Situation, dass eine gewisse Wahrscheinlichkeit existiert, mit der sich ein Gen ändern kann. Abhängig vom Typen des Gens, ist eine Änderung unterschiedlich formuliert, eine reelle Zahl mag sich anhand einer Normalverteilten Zufallsvariable ändern, eine natürliche Zahl mit $\pm1$ und ein Index mag einen zufälligen möglichen Index annehmen. Wichtig ist nur, dass potenziell neue Eigenschaften in eine Population eingeführt werden können.
Crossover beschreibt die Situation, dass zwei oder mehr Elternindividuuen zu einem Kindindividuum kombiniert werden. Auch hier ist die Implementierung nicht vorgeschrieben, wichtig ist nur, dass ein Kind als Kreuzung der Eltern erzeugt werden kann.
Es ist allerdings anzumerken, dass Crossover einen optionalen Teil von genetischen Algorithmen darstellt, einige Algorithmen, wie beispielsweise ($1 + \lambda$)-ES verzichten aus verschiedenen Gründen auf Crossover und mutieren ihre Populationen nur.
Diese beiden Methoden stellen sicher, dass neue Genotypen, und damit neue Lösungen generiert werden können, stellen aber keine Mechanismus zur Verfügung durch den der Algorithmus optimale Lösungen erreicht.
Der Mechanismus, der der Optimierung eine Richtung gibt ist die Selektion.
Diese agiert auf Phänotypen, sprich ausgedrückten Lösungen.
Für jede Lösung kann die Güte oder der Kosten einer Lösung, entsprechend Fitness oder Kosten genannt, 
mit einer Fitness- oder Kostenfunktion berechnet werden.
Ob eine Fitness- oder Kostenfunktion genutzt wird hängt von der Problemformulierung ab, und ist letztendlich eine Frage ob minimiert oder maximiert wird.
Die Fitness, bzw. der Kosten jedes Individuums kann dann ermittelt werden und die Selektion eliminiert dann schlechte Lösungen, sprich solche mit niedriger Fitness, bzw. hohen Kosten.
Dadurch werden in jeder Generation neue Individuen generiert und schlechte Individuen aussortiert, was Stück für Stück zu einer Verbesserung der Population führt.

\subsubsection{Divergente genetische Algorithmen}

Eine sehr häufige Anforderung an genetische Algorithmen ist die Einbindung von Divergenz, bzw. Diversität.
Dies hat verschiedene Gründe.
Einerseits führt eine niedrige Diversität der Individuen dazu, dass nur ein kleiner Bereich des Suchraums, nämlich der in dem die Individuen liegen abgesucht wird.
Sehr homogene Populationen können dadurch einfach in lokalen Optima stagnieren, da andere Optima zu weit im Suchraum entfernt sind.
In einer diversen Population ist das Springen aus lokalen Optima hingegen einfacher, und selbst wenn Populationen stagnieren, dann geschieht dies in mehreren Optima gleichzeitig, wodurch die Wahrscheinlichkeit in einem im globalen Vergleich gutes lokalen Optimum zu finden steigt.
Auch ist es nicht unbedingt wünschenswert eine sehr homogene Population als Ergebnis zu erhalten, da die Individuen mit hoher Wahrscheinlichkeit aller der gleichen Lösungsklasse angehören.
Wenn man eine diverse Population aus Individuen erhält können Aussagen über unterschiedliche Lösungsklassen getroffen werden, Lösungsklassen und ihre Qualität können miteinander verglichen werden, und je nachdem kann größere Erkenntnis erlangt werden, was eine qualitativ hochwertige Lösung ausmacht wodurch wiederum das gestellte Problem besser verstanden werden kann.

Es existieren verschiedenste Ansätze um Diversität zu gewährleisten, welche sind grundsätzlich in genotypische und phänotypische Ansätze aufteilen lassen, abhängig davon wo Diversitätsmanagement stattfindet.
Ansätze wie Niching\todo{cite}, gewährleisten genotypische Diversität durch die Ermittlung der genetischen Ähnlichkeit zweier Individuen.
Das hat den Vorteil, dass der Genotyp eines Individuums typischerweise ein Vektor ist, und eine Vielzahl von Ähnlichkeitsmetriken für Vektoren existiert.
Dadurch fällt die Definition, was Diversität ausmacht sehr leicht.
Auch ist die Berechnung einer Distanz zwischen Vektoren sehr effizient, was vorteilhaft ist, da die Berechnung von Diversität typischerweise sehr häufig stattfinden muss.
Allerdings hat es den Nachteil, dass, besonders wenn die Genotyp-zu-Phänotyps-Mapping Funktion komplex ist, genetische Distanz nicht funktionaler Distanz zwischen Lösungen enspricht.
D. h. es besteht die Möglichkeit, dass genetisch unähnliche Individuen trotzdem in die gleiche Lösungsklasse fallen.
Deshalb wurden Ansätze wie Novelty-Search\todo{cite} oder MAP-Elites\cite{Mouret.4202015} zum Diversitätsmanagement vorgeschlagen, die Diversität auf der Ebene, des Phänotyps bestimmen und somit funktionale Distanz messen.
Da der Phänotyp domänenspezifisch,  muss die Diversitätsmetrik für jede Domäne maßgeschneidert definiert werden, und es kann nicht auf Allgemeinlösungen zurückgegriffen werden.
Auch besteht eine erhebliche Limitierung bezüglich der Komplexität einer solche Diversitätsmetrik, da die Diversität typischerweise sehr häufig berechnet werden muss.

\subsubsection{MAP-Elites}

\label{sub:mapElites}
MAP-Elites \cite{Mouret.4202015} ist ein genetischer Algorithmus mit phänotypischem Diversitätsmanagement.
Das bedeutet, dass die Morphologie bzw. Funktionalität einer konkreten ausgedrückten Lösung, wie beispielsweise Volumen oder Krümmung eines Bauteils, betrachtet wird.
Dazu wird der Lösungsraum entlang beliebig vieler Feature-Dimensionen, d. h. Merkmalen der Lösungen, die unabhängig von der Zielfunktion sind, aufgeteilt.
Diesen Feature-Dimensionen wird ein Minimum, Maximums sowie eine Schrittweite zugewiesen um den Lösungsraum in Zellen zu diskretisieren.
Diese Diskretisierung zu Zellen wird häufig auch Karte genannt.
%Jede dieser Zellen stellt dabei eine Kombination der Eigenschaften dar.
Zu Beginn sind all diese Zellen leer, im Laufe des Algorithmus werden diese nach und nach gefüllt.
Jede Zelle kann aber nur maximal eine Lösung enthalten.
In jeder Generation werden aus den momentan in der Karten enthaltenen Lösung per Mutation Kinder erzeugt.
Jedes dieser Kinder wird erst bezüglich dessen Fitness evaluiert und dessen Phänotyp wird nach den gewählten Features kategorisiert.
Dadurch wird dem Kind abhängig von dessen Funktionalität eine Zelle zugewiesen, in der lokale Konkurrenz stattfindet.
Ist die zugewiesene Zelle leer befüllt das Kind die Zelle, befindet sich bereits ein Individuum in der Zelle werden stattdessen die Fitnesswerte der Beiden verglichen und das Individuum mit der höheren Fitness wird der Zelle zugewiesen.
Dadurch ist der Algorithmus divergent, denn dadurch, dass nur lokale Konkurrenz stattfindet kann ein Individuum nur durch ein phänotypisch ähnliches verdrängt werden, wodurch die phänotypische Diversität nicht sinkt.
Nicht nur wird eine Vielzahl von Lösungen generiert, die unterschiedliche Lösungsklassen abdecken, sondern die regelmäßig aufgeteilte Karte kann auch dabei helfen die Effekte, die die Features auf die Lösungsqualität haben zu verstehen.


\subsection{Surrogat-Modellierung}

\label{sub:surrogate}
Für die Selektion von Individuen innerhalb eines genetischen Algorithmus wird die Lösungsqualität dieser Individuen, typischerweise Fitness genannt, benötigt.
Außerdem findet die Auswertung der Fitnessfunktion innerhalb des genetischen Algorithmus sehr häufig statt.
Dies stellt bei relativ einfachen Fitnessfunktionen keine große Einschränkung dar, auf Problemdomänen in denen die Auswertung der Fitness eines Individuums allerdings komplexer und dadurch zeitaufwändiger wird, kann dies die Anwendbarkeit einfacher genetischer Algorithmen einschränken.

Aerodynamische Probleme, für die zeitaufwändige Simulationen nötig sind, gehören ohne Zweifel zu der Klasse von Problemen, für die die Anzahl der benötigten Funktionsauswertungen zu groß sind, als das der Algorithmus in vertretbarer Laufzeit abschließen kann.
Um genetische Taktiken auf eine solche Problemdomäne anzuwenden, wird eine Möglichkeit benötigt die benötigten Funktionsauswertungen erheblich zu reduzieren.
Eine solche Möglichkeit ist ein Surrogatmodell \cite{Jin.2011}\cite{Preen.2016}, eine Machine-Learning Modell, welches aufgrund echter Simulationsauswertungen trainiert wird, um deren Ergebnis annähernd vorherzusagen.
Eine Auswertung des Modells erfordert dabei nur einen winzigen Bruchteil des Aufwands, der für eine Simulation nötig wäre.
%Theoretisch sind verschiedenste Machine-Learning Verfahren für das Surrogatmodell denkbar, Gaußprozesse \cite{Rasmussen.2008} bieten sich durch die Eigenschaft an, dass sie neben einer Vorhersage auch immer ihre eigene Unsicherheit Liefern, und entsprechend Bereiche zeigen können, in denen große Unsicherheit herrscht, oder anders ausgedrückt in denen der Gaußprozess wenig weiß.
%Der Nachteil der hohen Speicher- und Berechnungskomplexität von Gaußprozessen ist durch die Limitierung auf eine geringe Anzahl an Simulationen und damit der Limitierung auf einen kleinen Trainingsdatensatz vernachlässigbar.

\subsection{Gaußprozesse}

Gaußprozesse sind ein in \cite{Rasmussen.2008} entwickeltes Machine-Learning Verfahren, mit welchem beliebige mathematische Funktionenen approximiert werden können. in großer Vorteil von Gaußprozessen ist, dass sie durch ihre Herkunft aus der Statistik neben die zu approximierende Funktion als Kombination aus Normalverteilungen modellieren.
Dadurch können Gaußprozesse neben einer Vorhersage auch die Varianz der Vorhersage an jedem Punkt liefern.
Das bedeutet, dass zu jedem Punkt auch die Unsicherheit bekannt ist, was für die Exploration des Funktionsraum
ein erheblicher Vorteil ist.
Der Hauptnachteil von Gaußprozessen ist der relativ hohe Speicher- und Rechenkomplexität \todo{komplexität}, da die Anzahl an Simulationen die durchgeführt werden kann aber ohnehin durch den Rechenaufwand, der mit diesen verbunden ist stark limitiert ist, wird die Anzahl an Trainingsdaten so gering bleiben, dass Komplexitätsüberlegungen hinfällig sind.

\subsection{SAIL}

SAIL (Surrogate-Assisted Illumination) vereint die in \ref{sub:mapElites} und \ref{sub:surrogate} beschriebenen Ansätze.
In \cite{Gaier.6152018} wurde gezeigt, dass dieser Ansatz erfolgreich auf 2D und 3D aerodynamische Domänen angewandt werden kann.
Es wurden Freiform-Deformationen auf 3D-Bauteile angewandt, welche dann wiederum bezüglich ihrer aerodynamischen Eigenschaften ausgewertet wurden, um ein Surrogat-Modell zu trainieren.

\subsection{Freiformdeformation}

Freiformdeformation\cite{Sederberg.1986} ist ein Verfahren zu Deformation von geometrischen Objekten.
Mithilfe der Freiformdeformation können beliebige dreidimensionale Meshes robust deformiert werden.
Dazu wird eine Box aus Kontrollpunkten erzeugt.
Jeder dieser Kontrollpunkte kann dann anhand von Verformungsparametern verschoben werden, wodurch für alle Punkte innerhalb der FFD-Box eine Verschiebung berechnet wird, die von der relativen Position des Punktes zum Kontrollpunkt abhängt.
Dadurch kann eine Deformation auf eine überschaubare Anzahl an Deformationsparametern reduziert werden.
Außerdem kann eine Deformation auf einige bestimmte Punkte und/oder Richtungen
\footnote{Deformation in x, y, z finden jeweils separat statt}
beschränkt werden, um die Komplexität weiter zu reduzieren.
Dadurch das nur die Punkte des Meshes ihre Position ändern, hat das Verfahren, den Vorteil das die Dreiecke erhalten bleiben und somit beispielsweise das Entstehen von Löchern bei korrekter Anwendung praktisch ausgeschlossen ist.

\subsection{OpenFOAM}

OpenFoam \todo{cite openfoam} ist eine Open-Source Programm zur Durchführung von Fluiddynamiksimulationen.
Berechnungen in OpenFOAM sind in sogenannten "Cases" organisiert auf die nacheinander OpenFoam-Funktionen angewandt werden
Diese Cases bestehen aus einer Basisstruktur, die Initiale Startparameter, sowie Dateien zur Steuerung von OpenFoam enthalten.
%Diese basis ist in den Ordnern \textit{domains/wheelcase/pe} und \textit{domains/escooter/pe} zu finden.
Diese Basis enthält typischerweise Skripts um die gesamte Kette aus verschiedenen OpenFoam Funktionen, die zur Durchführung einer Simulation notwendig sind, auszuführen (Allrun), sowie ein Skript, welches den Case wieder in den Case wieder in den Startzustand versetzt (Allclean).
Außerdem enthält diese basis den Ordner system, der C++-Dictionaries enthält, mit denen die einzelnen OPenFoam Funktionen parametrisiert und gesteuert werden.
Zuletzt befindet sich in diesem Ordner auch noch der Initiale Startzustand mit dem die Simulation beginnt (0org)
OpenFOAM bietet native Unterstützung von Parallelität über die MPI-Bibliothek \todo{cite mpi}.
Neben den Funktionen um die korrekte Aufteilung eines Cases auf mehrere Prozessoren aufzuteile und am Ende wieder zu rekonstruieren sind zwei Funktionen und deren dazugehörige Dateien hervorzuheben.

Die erste dieser Funktionen ist \textit{snappyHexMesh}, das durch \textit{snappyHexMeshDict} parametrisiert wird, mit welchem das aus dem STL-Orginalmesh das für die Fluiddynamiksimulation benötigte Mesh generiert wird. Durch die Parametrisierung von snappyHexMesh wird kontrolliert wie detailliert das Mesh an welchen Stellen ist.
Die wichtigen genutzten Definitionen in snappyHexMesh sind:
\todo{snappyhexmesh definitionen}

Die zweite dieser Funktione ist die eigentliche Fluiddynamiksimulation welche durch die Datei \textit{fvSolution} gesteuert wird. 
Es stehen verschiedene Simulationen für verschiedene Zwecke zur Verfügung.
Hier wurde \textit{simpleFoam} gewählt, da der Funktionsumfang für den Fokus dieser Arbeit völlig ausreicht.


\subsection{Constraints in Optimierungsprozessen}
Constraints sind eine Möglichkeit sekundäre Optimierungsparemter, welche neben dem primären Optimierungsziel ebenfalls eingehalten werden sollen, in einen Optimierungsprozess einzuarbeiten, ohne auf multivariate Optimierung zurückgreifen zu müssen.
Constraints lassen sich grundsätzlich in Soft Constraints, bei denen die Nichteinhaltung des Constraints zur Addition von Strafwerten auf die Optimierungsfunktion führt, und Hard Constraints, die eine binäre erfüllt/nicht erfüllt Auswahl treffen.
Welche dieser beiden Arten von Constraints genutzt wird, hängt stark von der Problemstellung ab.

\todo{Formulierung von Constraints aus nicht-mathematischer Formulierung}
\subsubsection{Hard Constraints}
Hard Constraints führen eine binäre Auswahl durch, bei der solche Lösungen, die den Constraint nicht erfüllen disqualifziert werden.
Sie stellen eine sehr einfache Lösung zur Implementierung von Constraints dar.
An der Stelle im Algorithmus an der neue Lösungen generiert werden werden alle ungültigen Lösungen herausgefiltert.
Dies hat den Vorteil, dass ungültige Lösungen niemals in den Algorithmus einfließen, und damit weder Rechenkapazitäten für nicht-nutzbare Lösungen genutzt werden, und solche Eigenschaften, durch die eine Lösung die Constraints verletzt vom Algorithmus überhaupt nicht in Erwägung gezogen werden.


\subsubsection{Soft Constraints}
Soft Constraints disqualifizieren Lösungen, die die Constraints verletzen, nicht.
Stattdessen wird beim Nichterfüllen von Constraints ein Strafwert auf die Kostenfunktion addiert, bzw. von einer Fitnessfunktion subtrahiert.
Das Lösungen, die die Constraints nicht erfüllen, nicht disqualifiziert werden, hat den Vorteil, dass viele Optimierungmethoden iterativ zu (lokalen) Optima konvergieren\footnote{Auch ein divergentes Optimierungsverfahren wie MAP-Elites konvergiert zu Optima, es wird nur sichergestellt, das zu einer Vielzahl lokaler Optima konvergiert wird}, 
und diese auch Lösungen, die die Constraints nicht erfüllen, als Trittbretter zu Lösungen, die die Constraints erfüllen, nutzen können.

Soft Constraint eignen sich in Fällen, in denen zu Beginn keine Lösungen bekannt sind, die die Constraints erfüllen, und in denen explorativ nach Lösungen gesucht werden soll, die die Constraints erfüllen.
Auch eignen sie sich für solche Probleme, in denen qualitative Unterschiede bezüglich der Stärke der Verletzung der Constraints zwischen unterschiedlichen Lösungen exisistieren können.
So kann argumentiert werden, dass im Falle, dass ein Constraint die Einhaltung eines Schwellenwerts ist, eine Lösung, die diesen um 1 überschreitet, qualitativ besser ist als eine, die diesen um 10 überschreitet.

Eine der größten Gefahren bei Soft Constraints ist, dass diese typischerweise als Kostenfunktionen formuliert werden, deren Wert mit der eigentlichen Zielfunktion der Optimierung kombiniert wird.
Eine solche Kombination enthält immer eine Gewichtung für alle Teilfunktionen die sie ausmacht.
Ist diese Gewichtung fehlerhaft parametrisiert, kann dies dazu führen, dass Teilfunktionen über- oder unterpriorisiert werden, und Constraints vom Algorithmus ignoriert werden, oder, dass nicht mehr nach dem primären Optimierungsziel optimiert wird.




\section{Methode}

\subsection{Allgemeines}

\subsubsection{Parametrisierung des Gaußprozesses}


\subsection{Radkästen des Velomobils}

Die erste Problemdomäne stellt die Optimierung der Radkästen eines Velomobils dar.
Da die momentanen Radkästen den Lenkausschlag des Velomobils erheblich einschränken, besteht das Ziel hierbei Radkästen zu generieren, die den maximalen oder zumindest einen weiteren Lenkausschlag ermöglichen und dabei trotzdem gute aerodynamische Eigenschaften aufweisen.

\subsubsection{Setup}
\subsubsection{OpenFOAM}
\subsubsection{Constraint}
Zur Erfüllung des Constraints wurden alle möglichen Radausschläge als Volumen modelliert (zu finden in ffd/turning\_volume.stl)

\begin{table}[h]
	\begin{tabularx}{.5\textwidth}{ll}\hline
		
		Position\footnote{Urpsprung des Koordinatensystems auf Boden an der Spitze des Velomobils. Linkshändiges Koordinatensystem mit z Höhenachse und Velomobil in -x-Richtung ausgerichtet} & \\
		\hline
		x &	$926mm$ \\
		y &	$343mm$ \\
		z &	$205mm$	\\
	\end{tabularx}
	\begin{tabularx}{.5\textwidth}{ll}\hline
		Rotation & \\ \hline
		$\phi$ & $16,6\degree$ \\
		$\theta$ & $0\degree$ \\
		$\psi$ & $0\degree$ \\
	\end{tabularx}
	\begin{tabularx}{.5\linewidth}{ll}
		Radius des Rads & $230mm$ \\
		Radausschlag & $\pm24,37\degree$\\
		
	\end{tabularx}

\label{tab:wheel_params}
\caption{Parameter Radausschlag}
\end{table}

Da ein Ziel darin bestand, den Constraint nicht als binäres, erfüllt/nicht erfüllt Problem zu definieren, da zwischen zwei Lösungen, die den Constraint nicht erfüllen trotzdem qualitative Unterschiede bestehen können wie stark der Constraint verletzt wird, wird als Constraint das Differenzvolumen des Radausschlags minus verformten Radkastens gewählt.
Da alle generierten Verformungen der Radkästen symmetrisch sind, wird der Constraint jeweils nur für den rechten Radkasten berechnet.
Zwar besteht keine direkte Kausalität zwischen diesem Volumen und dem maximalen möglichen Radausschlag aber die Vermutung, dass eine geringeres Volumen dieser Different mit größerem möglichen Radausschlag korreliert ist liegt nahe.
Zur Berechnung der Differenz zwischen Radausschlagsvolumen und Radkasten wird die Bibliothek \textit{gptoolbox} \todo{cite} genutzt, zur Generierung von Tetraedermeshes zur Volumenberechnung \textit{TetGen} \todo{cite}.
Um eine Differenz berechnen zu können wurde der rechte Radkasten zu einem geschlossenen Volumen gemacht, da die Constraintberechnung in jeder Generation für jedes Kind erfolgen muss wurde der Radkasten außerdem runtergesamplet \todo{klingt komisch? besseres wort} um die Berechnung  des Constraints ausreichend schnell durchführen zu können.
Aus dem Volumen wurde dann der Strafwert berechnet der in die Akquisefunktion integriert wurde.

\subsection{Wahl der Features}
Als Kategorien wurde die Breite des Velomobils gewählt.
Hierzu kann die Hypothese aufgestellt werden, dass die Breite des Velomobils mit der Erfüllung des Constraint korreliert ist. Es wäre also zu erwarten, dass breitere Velomobile den Constraint tendenziell besser erfüllen, als schmalere.
Auch kann die Hypothese aufgestellt werden, dass die Breite negativ mit dem Luftwiderstandsbeiwert korreliert ist.
Insgesamt wäre also zu vermuten, dass entlang dieser Achse
Als zweite Kategorie wurde die x-Koordinate des breitesten Punkts gewählt.
Da das Velombil in negative x-Richtung zeigt, bedeuten kleinere Werte hier, dass der Punkt weiter vorne liegt, größere, dass er weiter hinten liegt.
Zu dieser Kategorie lassen sich keine so direkten Hypothesen aufstellen wie zur ersteren.
Die Frage ob sich hier klare Tendenzen bezüglich den aerodynamischen Eigenschaften und/oder des Constraints aufzeigen ist Ziel der Untersuchung.

Auch die Kategorisierung erfolgte mit dem für die Berechnung des Constraints vereinfachten Modell des Radkastens, da auch die Kategorisierung so häufig stattfindet, dass die Verformung und Kategorisierung anhand des originalen feinen Radkasten Rechenaufwand und damit Zeit in Anspruch nimmt.

\subsection{E-Roller}

Die zweite Problemdomäne ist die explorative Untersuchung eines Bauteils an der Unterseite eines E-Rollers.
Hier besteht die Frage ob nicht-triviale Bauteile aerodynamische Vorteile bieten, und welche Eigenschaften solche Bauteile aufweisen.

\subsubsection{Setup}
\subsubsection{OpenFOAM}
\subsubsection{Constraint}
\subsubsection{Wahl der Features}





